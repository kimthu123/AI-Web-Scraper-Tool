

# ğŸ§  AI Research Article Scraper Web App

A lightweight web application built with **Python Flask** and **HTML/CSS/JS** to search, save, and download AI research articles from **arXiv** and **Semantic Scholar**.

---

## ğŸ“‚ Project Structure

| File / Folder | Description |
|----------------|-------------|
| `app.py` | Flask backend (runs the web server) |
| `scraper.py` | Handles scraping from arXiv and Semantic Scholar |
| `run_scraper.py` | CLI runner / bridge for direct testing |
| `search.py` | PHP bridge (legacy, replaced by Flask) |
| `index.html` | Frontend page (search, save, download, history) |
| `requirements.txt` | Dependency list |
| `output/` | (Optional) server-side saved outputs |

---

## âš™ï¸ Setup Instructions

### ğŸ§© Prerequisites
- Python **3.8+**
- Internet connection for API access (Semantic Scholar + arXiv)

### ğŸ“¦ Install Dependencies
```bash
py -m pip install flask flask-cors requests beautifulsoup4 python-dotenv openai requirements.txt

â–¶ï¸ Run the Application

py app.py

Then open your browser at:
ğŸ‘‰ http://127.0.0.1:5000

â¸»

ğŸš€ Features

ğŸ” 1. Search Articles
	â€¢	Enter a keyword and result limit (1â€“170).
	â€¢	Fetches papers from arXiv and Semantic Scholar via the backend.
	â€¢	Displays results in the left panel.

ğŸ’¾ 2. Save Selected
	â€¢	Check desired items in â€œSearch Resultsâ€ and click Save selected.
	â€¢	Saved articles appear in the middle â€œSaved Articlesâ€ list.
	â€¢	Saved data is stored in browser localStorage (persistent per browser origin).

ğŸ“¥ 3. Download Selected (JSON)
	â€¢	Check items in â€œSaved Articlesâ€ and click Download selected (JSON).
	â€¢	A .json file will be downloaded to your browserâ€™s default Downloads folder.
	â€¢	JSON structure follows format_article() from scraper.py.

ğŸ•“ 4. Search History
	â€¢	The right-hand â€œSearch Historyâ€ records up to 50 previous search queries.
	â€¢	You can â€œOpenâ€ a past keyword, â€œDeleteâ€ one entry, or â€œClear allâ€.

â¸»

ğŸ§¾ Example JSON Format

{
  "title": "Title",
  "date": "YYYY-MM-DD",
  "contentGroup": "Articles",
  "internalTags": ["Machine Learning"],
  "author": {
    "name": "Author Name",
    "email": "",
    "organization": ""
  },
  "publication": {
    "name": "arXiv / Semantic Scholar",
    "url": "https://..."
  },
  "publicTags": [],
  "summary": "Abstract text",
  "sourceUrl": "https://...",
  "language": "en",
  "readingTime": 3,
  "imageUrl": "",
  "relatedContent": [],
  "content": "<p>Abstract text</p>"
}


â¸»

âš ï¸ Notes & Limitations
	â€¢	The Semantic Scholar API allows up to 100 results per request, processed in paginated order.
	â€¢	arXiv supports higher batch sizes but may throttle excessive queries.
	â€¢	localStorage data is domain-specific (127.0.0.1 â‰  localhost).
	â€¢	All saved data is cleared when Incognito mode is turned off.
	â€¢	If GPT classification is not required, return "Uncategorized" in classify_topic_with_gpt().

â¸»

ğŸ•“ Version History
	â€¢	Base Flask integration
	â€¢	arXiv + Semantic Scholar scraping
	â€¢	Save to localStorage
	â€¢	Download selected as JSON
	â€¢	Search history (keywords)

â¸»

ğŸ“œ License

MIT License â€” Free for educational and research use.

This `.md` file preserves the structure and content of your original README but adds proper Markdown formatting for GitHub readability.
