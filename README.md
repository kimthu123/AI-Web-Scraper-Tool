# ğŸš€ AI Web Scraper Tool  
An AI-powered research scraper that automatically expands user queries, collects articles from multiple academic sources, filters duplicates, and outputs structured JSON data.  
Designed to speed up research â€” especially for topics like **AI tackling climate change**.

<p align="center">
  <img src="https://raw.githubusercontent.com/kimthu123/AI-Web-Scraper-Tool/main/preview.jpeg" width="85%" alt="Project Preview"/>
</p>

---

## ğŸ·ï¸ Badges

<p align="left">
  <img src="https://img.shields.io/badge/Language-Python-blue?style=flat-square"/>
  <img src="https://img.shields.io/badge/AI-OpenAI%20API-orange?style=flat-square"/>
  <img src="https://img.shields.io/badge/Scraper-Async%20Requests-green?style=flat-square"/>
  <img src="https://img.shields.io/badge/Output-JSON-success?style=flat-square"/>
</p>

---

## ğŸŒŸ Overview  
This scraper automates research by:

- ğŸ¤– Using **AI to expand** a user-generated query into multiple relevant subtopics.  
- ğŸ” Scraping articles from **arXiv, Semantic Scholar**, and more.  
- ğŸ§¹ Cleaning and **deduplicating metadata**.  
- ğŸ“¦ Exporting everything into a clean **JSON dataset**.  
- âš¡ Running fast using asynchronous Python scraping.

The tool is modular, extendable, and designed for real-world research workflows.

---

## âœ¨ Key Features

### ğŸ¤– AI Topic Expansion  
Uses **OpenAI GPT models** to transform one query into multiple subtopics.

### ğŸ” Multi-Source Scraping  
Collects articles based on each subtopic.  
Built with modular functions so new sources can easily be added.

### ğŸ§¹ Smart Filtering  
- Duplicate removal  
- Metadata normalization  
- Summary cleaning  
- Relevance filtering  

### ğŸ“¦ JSON Output  
Produces a clean JSON file ready for dashboards, ML pipelines, or external integrations.

---

## ğŸ›  Tech Stack

- ğŸ **Python 3**  
- ğŸ¤– **OpenAI API (GPT-3.5 / GPT-4)**  
- ğŸŒ **aiohttp / Requests**  
- ğŸ§¼ **BeautifulSoup / lxml**  
- ğŸ“ **JSON output**  
- ğŸ§° Optional: **VS Code Devcontainers**

---

## ğŸ“ Project Structure

```
ai-web-scraper/
â”‚
â”œâ”€â”€ expand_query.py       # AI expansion
â”œâ”€â”€ scraper.py            # Main scraping engine
â”œâ”€â”€ filters.py            # Filtering + cleanup
â”œâ”€â”€ output/
â”‚   â””â”€â”€ articles.json     # Exported file
â””â”€â”€ README.md
```

---

## âš™ï¸ How It Works

1. User enters a research topic  
2. AI expands it into multiple subtopics  
3. Scraper gathers articles for each one  
4. Filters clean the metadata  
5. Output saved as JSON  
6. Optional: Summaries via OpenAI  

---

## ğŸš€ Installation

Install dependencies:

```
pip install -r requirements.txt
```

Add your OpenAI API key inside `.env`:

```
OPENAI_API_KEY= ...
```

Run the scraper:

```
python scraper.py
```

Output file:

```
output/articles.json
```

---

## ğŸ“„ Example Output

```
{
  "title": "Using AI for Climate Prediction",
  "authors": ["J. Smith", "L. Johnson"],
  "published": "2024-02-10",
  "summary": "This paper explores...",
  "source": "arXiv",
  "topic": "AI for extreme weather prediction",
  "link": "https://arxiv.org/..."
}
```

---

## ğŸ¯ Purpose  
This project aims to automate academic research by:

- Reducing manual search time  
- Improving coverage across multiple research areas  
- Producing structured data for future AI analysis  
- Helping teams work faster with automated article extraction  

---

## ğŸ“¬ Contact

**Jace (Kim Thu Tran)**  
ğŸ“ Melbourne, Australia  
ğŸ“§ Email: trankimthu.160503@gmail.com  
ğŸ™ GitHub: https://github.com/kimthu123  
ğŸ”— LinkedIn: https://www.linkedin.com/in/kim-thu-tran-769211279/

<p align="center">
  <i>Thank you for checking out this project ğŸ’›</i>
</p>
